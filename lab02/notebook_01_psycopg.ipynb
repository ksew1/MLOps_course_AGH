{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ccf013-b6b8-4027-a0fe-d90c619c5782",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Psycopg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fab212-642d-46a9-9b1b-6502c4183694",
   "metadata": {},
   "source": [
    "Let's import `psycopg` and make a simple query. This requires:\n",
    "- preparing connection string (see [Postgres docs](https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING))\n",
    "- making a connection\n",
    "- creating a cursor\n",
    "- running a query on the cursor\n",
    "- parsing results\n",
    "\n",
    "See the code below and comments. As our query, we will read:\n",
    "- total number of trains stopping in Amsterdam\n",
    "- all trains that were late in Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea898094-1ff8-45be-b564-46ad3b9d07d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import psycopg\n",
    "\n",
    "# build the connection string\n",
    "host = \"localhost\"\n",
    "username = \"postgres\"\n",
    "password = \"postgres\"  # NEVER do this in real code, read from secure secrets file\n",
    "db_name = \"postgres\"\n",
    "\n",
    "db_conn_string = f\"host={host} user={username} password={password} dbname={db_name}\"\n",
    "print(db_conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fb2dd-e745-4cb3-9206-9d24afec820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_total_trains = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM services\n",
    "WHERE \"Stop:Station code\" = 'ASD'\n",
    "\"\"\"\n",
    "\n",
    "query_late_departure_trains = \"\"\"\n",
    "SELECT *\n",
    "FROM services\n",
    "WHERE \"Stop:Station code\" = 'ASD' AND \"Stop:Departure delay\" > 0\n",
    "\"\"\"\n",
    "\n",
    "# connect to the database (context manager will automatically close connection)\n",
    "with psycopg.connect(db_conn_string) as conn:\n",
    "    # create a cursor to execute commands\n",
    "    with conn.cursor() as cur:\n",
    "        # send query and fetch result\n",
    "        cur.execute(query_total_trains)\n",
    "        total_trains = cur.fetchone()\n",
    "\n",
    "        # send query and fetch results\n",
    "        cur.execute(query_late_departure_trains)\n",
    "        late_trains = cur.fetchall()\n",
    "\n",
    "print(\"Total trains:\", total_trains)\n",
    "\n",
    "print(\"Late trains:\")\n",
    "for record in late_trains[:3]:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500da471-53bf-43a2-998e-07d8f2a2d1af",
   "metadata": {},
   "source": [
    "**Connection** manages database session and network connection. It should always be used as a context manager, to close it after usage, since keeping \"dangling\" open connections wastes system resources. Opening and closing connections has some cost, so for batches of tasks it's good to keep the connection open.\n",
    "\n",
    "**Connection string** defines the Postgres connection. We can either build a string, or pass keyword arguments to `.connect()`.\n",
    "\n",
    "**Cursor** executes commands to the database. It will always use a transaction in psycopg. If you don't explicitly commit by calling `conn.commit()` inside the cursor block, it will roll back all changes. However, here we only read data, so this doesn't matter.\n",
    "\n",
    "**Results** are by default returned as a tuple for `.fetchone()` (even a single element), or list of tuples for `.fetchall()`. Types are automatically parsed, e.g. dates are `datetime.date` objects, with exact rules [in the documentation](https://www.psycopg.org/psycopg3/docs/basic/adapt.html).\n",
    "\n",
    "Tuples are not always convenient, and we have two main options:\n",
    "- use [row factory](https://www.psycopg.org/psycopg3/docs/advanced/rows.html#row-factories) to return dictionaries, named tuples, or a custom dataclass (you need to write it first)\n",
    "- use an ORM like SQLAlchemy or peewee\n",
    "\n",
    "Which one makes the most sense depends on a use case. If you use a custom dataclass, you are really close to using an ORM, so the line is often blurry.\n",
    "\n",
    "**Efficiency** typically has tradeoffs for large data. Processing data in sizes is typically necessary, as we can't easily load all data into memory like here. Smaller batches are sometimes more efficient within the database, particularly when we have proper indexes. For example, you may want to query for a single month at a time. However, too small batches will waste resources on network requests.\n",
    "\n",
    "**Column names** are often useful for automation, and we can get them without wasting a lot of memory for dictionaries. In fact, creating Pandas DataFrames from default tuples is actually faster and easier. We can get the list of column names from the cursor `description` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1eedc1-6868-4342-81e5-2dbb39b34b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(db_conn_string) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # LIMIT 0 for efficiency - we don't want rows, just column names\n",
    "        cur.execute(\"SELECT * FROM services LIMIT 0\")\n",
    "        colnames = [desc[0] for desc in cur.description]\n",
    "        print(colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab781a-809f-4c33-8d9d-2b7aa0a4395f",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "\n",
    "1. Write a query to get all trains that both arrived and departured late.\n",
    "\n",
    "2. Use a row factory to return dictionaries. \n",
    "```python\n",
    "    (from psycopg.rows import dict_row)\n",
    "```\n",
    "\n",
    "3. Save the result to file `data/late_train.jsonl` in JSON Lines format. `json` module will be useful.\n",
    "\n",
    "Since JSON does not have a default date or datetime format, we need to provide an explicit encoder for that. Pass this class to `json.dumps()` as `cls` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c9e66-846d-4a34-b2ab-25c388232448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "class DateEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (datetime.date, datetime.datetime)):\n",
    "            return obj.isoformat()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22cee1-ba3b-409c-8cd1-41e701441a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
